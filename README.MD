# 가위바위보 이미지 분류 모델
## 1. 사용된 모델
DenseNet121

DenseNet121은 "Densely Connected Convolutional Networks"의 줄임말로, 각 레이어가 모든 이전 레이어의 출력을 입력으로 받아들입니다. 이러한 구조는 정보의 흐름을 극대화하고, 그라디언트 소실 문제를 줄여줍니다.
### 특징:
- 높은 정보 전달 효율성: 모든 레이어가 이전 모든 레이어와 연결되어 있어 특징 전달이 매우 효율적입니다.
- 효율적인 파라미터 사용: 다른 깊은 네트워크에 비해 적은 수의 파라미터로 높은 성능을 발휘할 수 있습니다.
- 사전 학습: DenseNet121 모델은 ImageNet 데이터셋으로 사전 학습된 가중치를 사용하여 빠르고 효율적인 학습을 지원합니다.

> [!note] 적용: 이 모델은 가위바위보 이미지 분류 작업을 위해 마지막 레이어가 3개의 클래스로 조정되었습니다.
## 2. 데이터 전처리 및 증강
이미지 데이터의 다양성과 일반화 능력을 향상시키기 위해 다양한 전처리 및 데이터 증강 기법이 적용되었습니다.

- 이미지 크기 조정: 모든 이미지는 256x256 픽셀 크기로 리사이즈 되었습니다.
- 수평 뒤집기: 무작위로 이미지를 수평으로 뒤집어 이미지의 방향성에 대한 모델의 민감도를 줄였습니다.
- 회전: 무작위 회전을 통해 이미지의 다양한 각도에 대한 인식을 강화했습니다.
- 크롭 및 리사이즈: 무작위로 이미지를 크롭하고 다시 256x256으로 리사이즈하여 다양한 확대 및 축소 효과를 시뮬레이션했습니다.
- 색상 변화: 밝기, 대비, 채도, 색조를 무작위로 조정하여 조명 조건의 다양성을 추가했습니다.
- 텐서 변환: 이미지를 PyTorch 텐서로 변환하였습니다.
- 정규화: 사전 학습된 모델의 요구사항에 맞춰 각 이미지 채널을 정규화하였습니다.
- 평균값: [0.485, 0.456, 0.406]
- 표준편차: [0.229, 0.224, 0.225]
## 3. 학습 과정의 주요 특징
- 손실 함수: Cross Entropy Loss를 사용하여 모델의 출력과 실제 레이블 간의 차이를 계산했습니다. 클래스의 가중치는 균등하게 설정되었습니다.
- 최적화 알고리즘: Adam Optimizer를 사용하여 모델의 가중치를 업데이트했습니다. 이 알고리즘은 빠른 수렴 속도와 좋은 성능을 - 제공합니다.
- 학습률 조정: 학습이 진행됨에 따라 학습률을 점진적으로 감소시키는 StepLR 스케줄러를 사용했습니다. 이는 모델의 안정적인 수렴을 돕습니다.
- 학습 환경: Google Colab에서 NVIDIA T4 GPU를 사용하여 학습을 수행하였으며, 이로 인해 학습 시간이 크게 단축되었습니다.
- 에포크 수: 20개의 에포크 동안 학습이 진행되었으며, 이는 모델이 충분히 수렴할 수 있는 시간입니다.
## 4. 예상 학습 시간
DenseNet121 모델을 사용하여 3000장의 이미지를 학습하는 데 필요한 시간은 다음과 같이 예상됩니다:

- 한 에포크당 시간: 한 에포크당 약 1~2분 소요.
- 전체 학습 시간: 20 에포크 기준으로 총 학습 시간은 약 20분에서 40분 사이로 예상됩니다.
- 이 모델과 학습 방법을 통해 가위바위보 이미지를 효과적으로 분류할 수 있었습니다. DenseNet121의 높은 정보 전달 효율성과 강력한 특징 학습 능력 덕분에 이 작업에서 높은 성능을 얻을 수 있었습니다.